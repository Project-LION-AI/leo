{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os; sys.path.append(os.path.dirname(os.path.abspath(os.getcwd())))\n",
    "# libraries\n",
    "import os\n",
    "import openai\n",
    "import discord\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List\n",
    "\n",
    "import langchain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import Document\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "\n",
    "import chromadb\n",
    "\n",
    "from src.moderation import moderate_message\n",
    "from src.base import Message, Prompt, Conversation\n",
    "from src.utils import split_into_shorter_messages, close_thread, logger\n",
    "from src.moderation import (\n",
    "    send_moderation_flagged_message,\n",
    "    send_moderation_blocked_message,\n",
    ")\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "\n",
    "# def extract_docs(directory):\n",
    "#     doc = []\n",
    "#     for file in os.listdir(directory):\n",
    "#         with open(os.path.join(directory, file), \"r\") as f:\n",
    "#             doc += f.read()\n",
    "#     return doc\n",
    "# path=os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "# doc = extract_docs(f\"{path}//text\")\n",
    "#loader = DirectoryLoader('../', glob=\"**/*.txt\", loader_cls=TextLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs = loader.load()\n",
    "# #print(docs)\n",
    "# # \n",
    "# loader = DirectoryLoader('../', glob=\"**/*.txt\", loader_cls=TextLoader)\n",
    "# index = VectorstoreIndexCreator().from_loaders([loader])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "\n",
    "class BaseRetriever(ABC):\n",
    "    def __init__(self):\n",
    "        self.loader = DirectoryLoader('../', glob=\"**/*.txt\", loader_cls=TextLoader)\n",
    "        self.index = VectorstoreIndexCreator().from_loaders([self.loader])\n",
    "    @abstractmethod\n",
    "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        \"\"\"Get texts relevant for a query.\n",
    "\n",
    "        Args:\n",
    "            query: string to find relevant tests for\n",
    "\n",
    "        Returns:\n",
    "            List of relevant documents\n",
    "        \"\"\"\n",
    "    def ask_question(self, question):\n",
    "        #question = \"Who is researching decentralized leadership at talentDAO?\"\n",
    "        answer = self.index.query(question)\n",
    "        return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BaseRetriever.ask_question() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m BaseRetriever\u001b[39m.\u001b[39mask_question(question\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWho is researching decentralized leadership at talentDAO?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: BaseRetriever.ask_question() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "BaseRetriever.ask_question(question=\"Who is researching decentralized leadership at talentDAO?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader('../', glob=\"**/*.txt\", loader_cls=TextLoader)\n",
    "index = VectorstoreIndexCreator().from_loaders([loader])\n",
    "query = \"Who is researching decentralized leadership at talentDAO?\"\n",
    "index.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Lisa Wocken, PhD and Francisco Diaz (Pancho) are researching decentralized leadership at talentDAO.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Who is researching decentralized leadership at talentDAO?\"\n",
    "index.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Decentralized leadership is a set of capabilities and behaviors that anyone and any group of members can enact simultaneously and in various moments over time, versus a fixed label. It is about empowering the community of contributors and decentralizing and distributing power and authority throughout the organization. It is also about eliminating the dependency on any one individual.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is decentralized leadership?\"\n",
    "index.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' talentDAO is a community of organizational scientists, strategists, and researchers with a shared mission to unlock human potential in the decentralized, digital economy. We conduct scientific research that helps DAOs thrive while educating the public on the greater decency and agency offered from this decentralized future of work.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is talentDAO?\"\n",
    "index.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' k3nn.eth is Kenneth Francis, an industrial psychologist interested in using data science to improve human systems.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Who is k3nn.eth?\"\n",
    "index.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Ask a question to the bot about the talentDAO database.\"\"\"\n",
    "import discord\n",
    "import faiss\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import VectorDBQAWithSourcesChain\n",
    "import pickle\n",
    "import argparse\n",
    "from src.completion import CompletionResult, CompletionData\n",
    "from src.base import Message\n",
    "from src.completion import generate_completion_response\n",
    "\n",
    "# Load our LangChain index\n",
    "index = faiss.read_index(\"/Users/kennycavanagh/Desktop/files/lab/repositories/leo/docs.index\")\n",
    "# open our pickle file\n",
    "with open(\"/Users/kennycavanagh/Desktop/files/lab/repositories/leo/faiss_store.pkl\", \"rb\") as f:\n",
    "    store = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import VectorDBQA\n",
    "store.index = index\n",
    "chain = RetrievalQA.from_llm(llm=OpenAI(temperature=0), vectorstore=store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "chain = load_qa_chain(llm, chain_type=\"map_rerank\", verbose=True, return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Chain.__call__() got an unexpected keyword argument 'question'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mWho is researching decentralized leadership at talentDAO?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m chain(question\u001b[39m=\u001b[39mquery)\n",
      "\u001b[0;31mTypeError\u001b[0m: Chain.__call__() got an unexpected keyword argument 'question'"
     ]
    }
   ],
   "source": [
    "query = \"Who is researching decentralized leadership at talentDAO?\"\n",
    "\n",
    "chain.run(input_documents=index, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import OpenAI, VectorDBQA\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "import magic\n",
    "import os\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader('/Users/kennycavanagh/Desktop/files/lab/repositories/leo/text', glob='**/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Chroma using direct local API.\n",
      "Using DuckDB in-memory for database. Data will be transient.\n",
      "Exiting: Cleaning up .chroma directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kennycavanagh/anaconda3/envs/leo_env/lib/python3.11/site-packages/langchain/chains/retrieval_qa/base.py:152: UserWarning: `VectorDBQA` is deprecated - please use `from langchain.chains import RetrievalQA`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=os.environ['OPENAI_API_KEY'])\n",
    "docsearch = Chroma.from_documents(texts, embeddings)\n",
    "qa = VectorDBQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", vectorstore=docsearch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The talentDAO core team includes renee daos, lisa wocken, kenneth francis, Nemo, Pancho, Mr. Nobodody, Sherif, Prof Burns, and Lia.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Who is part of the talentDAO core team?\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# index = faiss.read_index(\"/Users/kennycavanagh/Desktop/files/lab/repositories/leo/docs.index\")\n",
    "# # open our pickle file\n",
    "# with open(\"/Users/kennycavanagh/Desktop/files/lab/repositories/leo/faiss_store.pkl\", \"rb\") as f:\n",
    "#     store = pickle.load(f)\n",
    "\n",
    "# store.index = index\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=docsearch.as_retriever())\n",
    "retriever = docsearch.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The talentDAO core team includes renee daos, lisa wocken, kenneth francis, Nemo, Pancho, Mr. Nobody, Sherif, Prof Burns, and Lia.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Who is part of the talentDAO core team?\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Chroma using direct local API.\n",
      "Using DuckDB in-memory for database. Data will be transient.\n",
      " The talentDAO core team includes renee daos, lisa wocken, kenneth francis, Nemo, Pancho, Mr. Nobody, Sherif, Prof Burns, and Lia.\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"my_api_key\"\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "dir = '/Users/kennycavanagh/Desktop/files/lab/repositories/leo/text'\n",
    "def load_documents(directory):\n",
    "    loader = DirectoryLoader(directory, glob='**/*.txt')\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "def process_documents(documents):\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=os.environ['OPENAI_API_KEY'])\n",
    "    docsearch = Chroma.from_documents(texts, embeddings)\n",
    "    return docsearch\n",
    "\n",
    "\n",
    "def load_qa_chain(llm, chain_type=\"stuff\"):\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, chain_type=chain_type, retriever=docsearch.as_retriever())\n",
    "    return qa\n",
    "\n",
    "def ask_question(qa, question):\n",
    "    answer = qa.run(question)\n",
    "    return answer\n",
    "\n",
    "documents = load_documents(dir)\n",
    "docsearch = process_documents(documents)\n",
    "llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "qa = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "question = \"Who is part of the talentDAO core team?\"\n",
    "answer = ask_question(qa, question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who is part of the talentDAO core team?\"\n",
    "qa.run(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5bd071745ec933c7984f36109de0afbdd84ca66c5dc68223d43ac36c0235fc15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
